{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/Pratheek/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "[Start]\n",
    "   │\n",
    "   ▼\n",
    "[Scrape webpage using the provided URL]\n",
    "   │\n",
    "   ▼\n",
    "[Extract page content with BeautifulSoup]\n",
    "   │\n",
    "   ▼\n",
    "[Save the scraped text to a .txt file]\n",
    "   │\n",
    "   ▼\n",
    "[Segment the full text into sentences (using NLTK)]\n",
    "   │\n",
    "   ▼\n",
    "[Run NER (Hugging Face transformer) on the full text]\n",
    "   │\n",
    "   ▼\n",
    "[Build a mapping of recognized person names to unique voice IDs]\n",
    "   │\n",
    "   ▼\n",
    "[For each sentence in the text]\n",
    "   │\n",
    "   ├──► [Check if the sentence contains any recognized name]\n",
    "   │         │\n",
    "   │         ├─ Yes: Assign the corresponding voice (e.g., Voice 3 for \"Li Luo\")\n",
    "   │         │\n",
    "   │         └─ No: Assign narrator voice (Voice 1)\n",
    "   │\n",
    "   ▼\n",
    "[Use the TTS engine (pyttsx3) to speak the sentence using the assigned voice]\n",
    "   │\n",
    "   ▼\n",
    "[Repeat for all sentences]\n",
    "   │\n",
    "   ▼\n",
    "[End]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from transformers import pipeline\n",
    "import pyttsx3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure that NLTK's sentence tokenizer data is downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "# ---------- Step 1: Scraping the webpage ---------- #\n",
    "def scrape_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error fetching page: Status code {response.status_code}\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Extract text from the whole page. You may need to adjust this selector.\n",
    "    text = soup.get_text(separator='\\n')\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_text_to_file(text, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "    print(f\"Saved scraped content to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Step 2: Segmenting text into sentences ---------- #\n",
    "def get_sentences(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Step 3: Named Entity Recognition (NER) ---------- #\n",
    "def extract_names(text):\n",
    "    # Load the NER pipeline with aggregation to combine tokens of full names\n",
    "    ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", aggregation_strategy=\"simple\")\n",
    "    entities = ner_pipeline(text)\n",
    "    # Build a mapping of unique person names to a unique voice ID\n",
    "    # (Here, we reserve Voice 1 for the narrator; person names start at Voice 2)\n",
    "    recognized_names = {}\n",
    "    for entity in entities:\n",
    "        if entity.get(\"entity_group\") == \"PER\":\n",
    "            name = entity[\"word\"]\n",
    "            if name not in recognized_names:\n",
    "                # Assign voice id starting at 2 (narrator is 1)\n",
    "                recognized_names[name] = len(recognized_names) + 2\n",
    "    return recognized_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Step 4: TTS with voice assignment ---------- #\n",
    "def speak_sentence(engine, sentence, voice_id, voices):\n",
    "    # Select a voice based on voice_id (cycle if not enough voices)\n",
    "    voice_index = (voice_id - 1) % len(voices)\n",
    "    engine.setProperty('voice', voices[voice_index].id)\n",
    "    print(f\"Using Voice {voice_id} to say: {sentence}\")\n",
    "    engine.say(sentence)\n",
    "    engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assign_voice_to_sentence(sentence, names_voice_map):\n",
    "    \"\"\"\n",
    "    Check if any recognized name from the map appears in the sentence.\n",
    "    Returns the corresponding voice id if a match is found; otherwise, returns 1 (narrator).\n",
    "    \"\"\"\n",
    "    # For robustness, do a case-insensitive search.\n",
    "    for name, voice_id in names_voice_map.items():\n",
    "        # Use regex word boundaries to avoid partial matches.\n",
    "        if re.search(r'\\b' + re.escape(name) + r'\\b', sentence, re.IGNORECASE):\n",
    "            return voice_id\n",
    "    return 1  # Narrator voice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Main Process ---------- #\n",
    "if __name__ == '__main__':\n",
    "    # URL to scrape (provided by the user)\n",
    "    url = \"https://readnovelfull.com/absolute-resonance/chapter-1481-four-sword-realm-goddess-divineflame-mirror.html\"\n",
    "    \n",
    "    try:\n",
    "        # Scrape and save page content\n",
    "        full_text = scrape_page(url)\n",
    "        save_text_to_file(full_text, \"scraped_page.txt\")\n",
    "        \n",
    "        # Segment the full text into sentences\n",
    "        sentences = get_sentences(full_text)\n",
    "        print(f\"Total sentences extracted: {len(sentences)}\")\n",
    "        \n",
    "        # Extract recognized person names from the entire text\n",
    "        names_voice_map = extract_names(full_text)\n",
    "        print(\"Recognized Names and their Assigned Voice IDs:\")\n",
    "        for name, vid in names_voice_map.items():\n",
    "            print(f\"  {name}: Voice {vid}\")\n",
    "        \n",
    "        # Initialize TTS engine (pyttsx3)\n",
    "        engine = pyttsx3.init()\n",
    "        voices = engine.getProperty('voices')\n",
    "        if not voices:\n",
    "            raise Exception(\"No voices found in TTS engine.\")\n",
    "        \n",
    "        # ---------- Step 5: Process each sentence ---------- #\n",
    "        for sentence in sentences:\n",
    "            # Determine which voice to use for this sentence\n",
    "            assigned_voice = assign_voice_to_sentence(sentence, names_voice_map)\n",
    "            speak_sentence(engine, sentence, assigned_voice, voices)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
